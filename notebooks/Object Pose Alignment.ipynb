{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23eb47d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T09:27:17.224710Z",
     "start_time": "2023-11-24T09:27:17.222083Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "grasp_transfer_path = os.getenv(\"GRASP_TRANSFER_SOURCE_DIR\")\n",
    "sys.path.insert(0,grasp_transfer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696b726",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T09:27:19.951705Z",
     "start_time": "2023-11-24T09:27:17.500508Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataio import *\n",
    "from networks import *\n",
    "from torch.utils.data import DataLoader\n",
    "from visualize import *\n",
    "from trimesh.viewer import windowed\n",
    "import time\n",
    "from sdf_estimator import *\n",
    "from utility import *\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "from skimage import measure\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import sys, os\n",
    "import plotly.offline    \n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "import trimesh\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def compute_trimesh_chamfer(gt_mesh, gen_mesh, num_mesh_samples=30000):\n",
    "    \"\"\"\n",
    "    This function computes a symmetric chamfer distance, i.e. the sum of both chamfers.\n",
    "    gt_points: trimesh.points.PointCloud of just poins, sampled from the surface (see\n",
    "               compute_metrics.ply for more documentation)\n",
    "    gen_mesh: trimesh.base.Trimesh of output mesh from whichever autoencoding reconstruction\n",
    "              method\n",
    "    Reference: DeepSDF, https://github.com/facebookresearch/DeepSDF/blob/main/deep_sdf/metrics/chamfer.py\n",
    "    \"\"\"\n",
    "\n",
    "    gt_points_sampled = trimesh.sample.sample_surface(gt_mesh, num_mesh_samples)[0]\n",
    "    \n",
    "    gen_points_sampled = trimesh.sample.sample_surface(gen_mesh, num_mesh_samples)[0]\n",
    "\n",
    "\n",
    "    # one direction\n",
    "    gen_points_kd_tree = KDTree(gen_points_sampled)\n",
    "    one_distances, one_vertex_ids = gen_points_kd_tree.query(gt_points_sampled)\n",
    "    gt_to_gen_chamfer = np.mean(np.square(one_distances))\n",
    "\n",
    "    # other direction\n",
    "    gt_points_kd_tree = KDTree(gt_points_sampled)\n",
    "    two_distances, two_vertex_ids = gt_points_kd_tree.query(gen_points_sampled)\n",
    "    gen_to_gt_chamfer = np.mean(np.square(two_distances))\n",
    "\n",
    "    return gt_to_gen_chamfer + gen_to_gt_chamfer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2694a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T09:27:19.961346Z",
     "start_time": "2023-11-24T09:27:19.953665Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_of_scenes = 64\n",
    "for obj_name in ['mugs','chairs','planes','cars']: # \n",
    "    for seed in [10,20,30,40,50]:\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        path_to_mugs = glob.glob(\"../datasets/\"+ obj_name +\"/*\")\n",
    "        obj_list= [obj_path for obj_path in np.random.choice(path_to_mugs, num_of_scenes,replace=False)]\n",
    "        sdf_dataset = Shape_SDF_Dataset_Noisy(obj_list,num_of_scenes,8000)\n",
    "        dataloader = DataLoader(sdf_dataset, shuffle=True,batch_size=4,\n",
    "                                num_workers=0, drop_last = True)\n",
    "    \n",
    "        output_path = '../outputs/train_'+ obj_name +'_'+ str(seed)\n",
    "        \n",
    "        os.mkdir(output_path)\n",
    "        with open(output_path +'/obj_list.pickle', 'wb') as handle:\n",
    "            pickle.dump(obj_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        np.save(output_path +'/random_poses', sdf_dataset.random_poses)\n",
    "        model = MyNet(num_of_scenes,affine=False)\n",
    "        model.to(device=torch.device('cuda:0'))\n",
    "        train_dataloader=dataloader\n",
    "        optim = torch.optim.Adam([\n",
    "                        {'params': model.sdf_net.parameters()},\n",
    "                        {'params': model.hyper_net.parameters()},\n",
    "                        {'params': model.latent_codes.parameters(), 'lr': 1e-3},\n",
    "                        {'params': model.se3_refine.parameters(), 'lr': 1e-3},\n",
    "                    ],\n",
    "            lr=1e-4)\n",
    "        total_steps=0\n",
    "        epochs=2000\n",
    "        with tqdm(total=len(train_dataloader) * epochs) as pbar:\n",
    "            train_losses = []\n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                for step, (model_input, gt) in enumerate(train_dataloader):\n",
    "                    start_time = time.time()\n",
    "                    model_input = {key: value.cuda() for key, value in model_input.items()}\n",
    "                    gt = {key: value.cuda() for key, value in gt.items()}\n",
    "\n",
    "                    losses = model(model_input,gt,epoch)\n",
    "\n",
    "                    train_loss = 0.\n",
    "                    for loss_name, loss in losses.items():\n",
    "                        single_loss = loss.mean()\n",
    "                        train_loss += single_loss\n",
    "\n",
    "                    train_losses.append(train_loss.item())\n",
    "                    optim.zero_grad()\n",
    "                    train_loss.backward()\n",
    "                    optim.step()\n",
    "                    pbar.update(1)\n",
    "                    pbar.set_postfix(loss=train_loss.item(), time=time.time() - start_time, epoch=epoch)\n",
    "                    total_steps += 1\n",
    "        RTs = model.get_refine_poses(torch.arange(0,num_of_scenes).cuda())[0].cpu().detach().numpy()\n",
    "        RT_base = find_inverse_RT_3x4(model.get_refine_poses(torch.arange(0,64).cuda(),affine=False).cpu().detach().numpy()[0])\n",
    "\n",
    "        torch.save(model.state_dict(), output_path +'/model')\n",
    "        try:\n",
    "            chamfer_distances_reconstructed = np.zeros((num_of_scenes-1,)) \n",
    "            chamfer_distances_perturbed = np.zeros((num_of_scenes-1,)) \n",
    "            chamfer_distances_perturbed_transformed = np.zeros((num_of_scenes-1,)) \n",
    "            obj_ind_counter = 0\n",
    "            for index in range(1,num_of_scenes-1): # \n",
    "                #\n",
    "                color = np.random.rand(3) * 255\n",
    "                v,t,_ = estimate_mesh_from_model(model, 2000, index, 128)\n",
    "\n",
    "                mesh2 = trimesh.Trimesh(vertices=sdf_dataset.meshes[index].vertices, faces=sdf_dataset.meshes[index].faces,face_colors = color)\n",
    "                translations,scale = compute_unit_sphere_transform(mesh2)\n",
    "                \n",
    "                mesh3 = trimesh.Trimesh(vertices=sdf_dataset.meshes_transformed[index].vertices, faces=sdf_dataset.meshes_transformed[index].faces,face_colors = color)\n",
    "                mesh = trimesh.Trimesh(vertices=v/scale-translations, faces=t,face_colors = color)   \n",
    "                mesh.apply_transform(RT_base)\n",
    "\n",
    "                transformed_transformed_points = (RTs[index]@to_hom_np(sdf_dataset.meshes_transformed[index].vertices).T).T    \n",
    "                mesh4 = trimesh.Trimesh(vertices=transformed_transformed_points, \n",
    "                                        faces=sdf_dataset.meshes_transformed[index].faces,face_colors = color)  \n",
    "                \n",
    "                chamfer_distances_reconstructed[index-1] = compute_trimesh_chamfer(mesh,mesh2)\n",
    "                chamfer_distances_perturbed[index-1] = compute_trimesh_chamfer(mesh3,mesh2)\n",
    "                chamfer_distances_perturbed_transformed[index-1] = compute_trimesh_chamfer(mesh4,mesh2)\n",
    "                del mesh,mesh2,mesh3,mesh4\n",
    "            np.save(output_path +'/chamfer_distances_reconstructed',\n",
    "                    chamfer_distances_reconstructed)\n",
    "            np.save(output_path +'/chamfer_distances_perturbed',\n",
    "                    chamfer_distances_perturbed)\n",
    "            np.save(output_path +'/chamfer_distances_perturbed_transformed',\n",
    "                    chamfer_distances_perturbed_transformed)            \n",
    "        except:\n",
    "            print(\"There are some errors in \" + obj_name +'_'+ str(seed))\n",
    "        del model, sdf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d244c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T09:29:08.232448Z",
     "start_time": "2023-11-24T09:29:08.221850Z"
    }
   },
   "outputs": [],
   "source": [
    "cdist_reconstructed_dict = dict()\n",
    "cdist_perturbed_dict = dict()\n",
    "cdist_perturbed_transformed_dict = dict()\n",
    "for obj_name in ['mugs','chairs','planes','cars']:\n",
    "    cdist_reconstructed_dict[obj_name] = list()\n",
    "    cdist_reconstructed_no_smoothing_dict[obj_name] = list()\n",
    "    cdist_perturbed_dict[obj_name] = list()\n",
    "    cdist_perturbed_transformed_dict[obj_name] = list()\n",
    "    for seed in [10,20,30,40,50]:\n",
    "        output_path = '../outputs/train_'+ obj_name +'_'+ str(seed)\n",
    "        cdist_reconstructed = np.load(output_path +'/chamfer_distances_reconstructed.npy')\n",
    "        cdist_perturbed = np.load(output_path +'/chamfer_distances_perturbed.npy')        \n",
    "        cdist_perturbed_transformed = np.load(output_path +'/chamfer_distances_perturbed_transformed.npy')\n",
    "\n",
    "        cdist_reconstructed_dict[obj_name].append(np.mean(cdist_reconstructed))\n",
    "        cdist_perturbed_dict[obj_name].append(np.mean(cdist_perturbed))\n",
    "        cdist_perturbed_transformed_dict[obj_name].append(np.mean(cdist_perturbed_transformed))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb298f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T11:19:36.352867Z",
     "start_time": "2023-11-24T11:19:36.345877Z"
    }
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "rows= list()\n",
    "for pair in ['mugs','chairs','planes','cars']:\n",
    "    row_name = pair\n",
    "    row = list()\n",
    "    row.append(row_name)\n",
    "    row.append(str(round(np.mean(cdist_reconstructed_dict[row_name]),4))+ ' \\pm ' +\n",
    "               str(round(np.std(cdist_reconstructed_dict[row_name]),4)))\n",
    "    row.append(str(round(np.mean(cdist_perturbed_dict[row_name]),4))+ ' \\pm ' +\n",
    "               str(round(np.std(cdist_perturbed_dict[row_name]),4)))    \n",
    "    rows.append(row)\n",
    "col_names = ['Object Names','Our Method','Pre-Alignment']\n",
    "  \n",
    "#display table\n",
    "print(tabulate(rows, headers=col_names, tablefmt=\"fancy_grid\"))\n",
    "\n",
    "# For genering latex code for the table\n",
    "# rows=list()\n",
    "# for pair in ['mugs','chairs','planes','cars']:\n",
    "#     row_name = pair\n",
    "#     row = ''\n",
    "#     row += row_name + ' & '\n",
    "#     row += str(round(np.mean(cdist_reconstructed_dict[row_name]),4))+ ' $\\pm$ ' + \\\n",
    "#                str(round(np.std(cdist_reconstructed_dict[row_name]),4))\n",
    "#     row += ' & '\n",
    "#     row += str(round(np.mean(cdist_perturbed_dict[row_name]),4))+ ' $\\pm$ ' + \\\n",
    "#                str(round(np.std(cdist_perturbed_dict[row_name]),4))    \n",
    "#     print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3eef53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T09:37:22.381878Z",
     "start_time": "2023-11-24T09:37:22.366363Z"
    }
   },
   "outputs": [],
   "source": [
    "obj_name = 'mugs'\n",
    "seed=10\n",
    "num_of_scenes=64\n",
    "output_path = '../outputs/train_'+ obj_name +'_'+ str(seed)\n",
    "\n",
    "with open(output_path+'/obj_list.pickle', 'rb') as handle:\n",
    "    obj_list = pickle.load(handle)\n",
    "random_poses = np.load(output_path +'/random_poses.npy')\n",
    "sdf_dataset = Shape_SDF_Dataset_Noisy(obj_list,num_of_scenes,8000,random_poses=random_poses)\n",
    "dataloader = DataLoader(sdf_dataset, shuffle=True,batch_size=4, pin_memory=True, num_workers=0, drop_last = True)\n",
    "model = MyNet(num_of_scenes,affine=False)\n",
    "model.to(device=torch.device('cuda:0'))\n",
    "model.load_state_dict(torch.load(output_path+'/model'))#my_model\n",
    "model.eval()\n",
    "\n",
    "RT_base = find_inverse_RT_3x4(model.get_refine_poses(torch.arange(0,64).cuda(),affine=False).cpu().detach().numpy()[0])\n",
    "translation_base, scale_base = compute_unit_sphere_transform(sdf_dataset.meshes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f672b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T11:17:40.908569Z",
     "start_time": "2023-11-24T11:17:26.392469Z"
    }
   },
   "outputs": [],
   "source": [
    "R_viz_fix=np.eye(4)\n",
    "\n",
    "R_viz_fix[:3,:3] = R.from_rotvec(np.array([ 0,-5*np.pi/6, 0])).as_matrix() @R.from_rotvec(np.array([ -np.pi/9,0, -np.pi/9])).as_matrix()\n",
    "\n",
    "# Used Camera/Color Fixes: R_viz_fix -- color\n",
    "### MUG ::: R.from_rotvec(np.array([ 1*np.pi/6,0, 0])).as_matrix() [125,50,200]\n",
    "### CAR ::: R.from_rotvec(np.array([0, -7*np.pi/9, 0])).as_matrix()@R.from_rotvec(np.array([-np.pi/6, 0, -np.pi/6])).as_matrix(), [50,50,250]\n",
    "### CHAIRS ::: R.from_rotvec(np.array([ 0,-5*np.pi/6, 0])).as_matrix() @R.from_rotvec(np.array([ -np.pi/9,0, -np.pi/9])).as_matrix() [50,200,125]\n",
    "### PLANES ::: R.from_rotvec(np.array([ 0,-5*np.pi/6, 0])).as_matrix() @R.from_rotvec(np.array([ -np.pi/9,0, -np.pi/9])).as_matrix(), [175,100,50]\n",
    "color =  [175,100,50]\n",
    "for index in range(4):\n",
    "    print(index)\n",
    "    mesh_list=list()\n",
    "\n",
    "    translation, scale = compute_unit_sphere_transform(sdf_dataset.meshes[index])\n",
    "\n",
    "    mesh = trimesh.Trimesh(vertices=sdf_dataset.meshes[index].vertices*scale, \n",
    "                            faces=sdf_dataset.meshes[index].faces,\n",
    "                            face_colors = [color[0],color[1],color[2],125])\n",
    "    mesh2 = trimesh.Trimesh(vertices=sdf_dataset.meshes_transformed[index].vertices*scale,\n",
    "                            faces=sdf_dataset.meshes_transformed[index].faces,\n",
    "                            face_colors = color)\n",
    "    mesh.apply_transform(R_viz_fix)\n",
    "    mesh2.apply_transform(R_viz_fix)\n",
    "\n",
    "    translation,scale = compute_unit_sphere_transform(sdf_dataset.meshes[index])\n",
    "\n",
    "    mesh4 = trimesh.Trimesh(vertices=sdf_dataset.meshes[index].vertices*scale, \n",
    "                            faces=sdf_dataset.meshes[index].faces,\n",
    "                            face_colors = [color[0],color[1],color[2],125])\n",
    "\n",
    "    v,t,_ = estimate_mesh_from_model(model, 1000, index, 128)\n",
    "    mesh3 = trimesh.Trimesh(vertices=v, faces=t,face_colors = color)\n",
    "    mesh3.apply_translation(-scale * translation)  \n",
    "    mesh3.apply_transform(RT_base)\n",
    "    mesh3.apply_transform(R_viz_fix)\n",
    "    mesh4.apply_transform(R_viz_fix)\n",
    "\n",
    "    mesh3.apply_translation([2.5, 0, 0])  \n",
    "    mesh4.apply_translation([2.5, 0, 0])  \n",
    "\n",
    "    mesh_list.append(mesh)\n",
    "    mesh_list.append(mesh2)\n",
    "    mesh_list.append(mesh3)\n",
    "    mesh_list.append(mesh4)\n",
    "\n",
    "    scene = trimesh.Scene()\n",
    "    scene.add_geometry(mesh_list)\n",
    "    window = windowed.SceneViewer(scene,smooth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55435c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T11:19:12.564087Z",
     "start_time": "2023-11-24T11:19:06.854357Z"
    }
   },
   "outputs": [],
   "source": [
    "# For Better Looking Meshes\n",
    "import pyrender\n",
    "mesh_list_pyrender = list()\n",
    "scene = pyrender.Scene()\n",
    "for mesh in mesh_list:\n",
    "    mesh_pyrender = pyrender.Mesh.from_trimesh(mesh, smooth=False)\n",
    "    scene.add(mesh_pyrender)\n",
    "cam = pyrender.PerspectiveCamera(yfov=(np.pi / 3.0))\n",
    "cam_pose = np.array([\n",
    "    [1,  0,  0, 0],\n",
    "    [0,  1,  0, 0.0],\n",
    "    [0,  0,  1, 2],\n",
    "    [0,  0,  0, 1.0]\n",
    "])\n",
    "cam_node = scene.add(cam, pose=cam_pose)\n",
    "\n",
    "pyrender.Viewer(scene,central_node=mesh, use_raymond_lighting=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grasp_transfer_venv",
   "language": "python",
   "name": "grasp_transfer_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
