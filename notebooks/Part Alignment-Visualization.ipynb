{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T16:32:46.075771Z",
     "start_time": "2023-12-05T16:32:46.069783Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "grasp_transfer_path = os.getenv(\"GRASP_TRANSFER_SOURCE_DIR\")\n",
    "sys.path.insert(0,grasp_transfer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T16:32:49.733670Z",
     "start_time": "2023-12-05T16:32:46.527172Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataio import *\n",
    "from networks import *\n",
    "from torch.utils.data import DataLoader\n",
    "from visualize import *\n",
    "from trimesh.viewer import windowed\n",
    "import time\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sdf_estimator import *\n",
    "import open3d as o3d\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import ipywidgets as widgets\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "from utility import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T16:32:49.743490Z",
     "start_time": "2023-12-05T16:32:49.735375Z"
    }
   },
   "outputs": [],
   "source": [
    "part_name = \"handle\" # \"rim\"\n",
    "with open(\"../configs/part_dataset_info.yaml\", 'r') as stream:\n",
    "    dataset_config = yaml.safe_load(stream)\n",
    "train = dataset_config['train_list']\n",
    "val = dataset_config['val_list']\n",
    "part = dataset_config['part_'+part_name]    \n",
    "output_name = \"../outputs/\"+part_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T16:33:07.333055Z",
     "start_time": "2023-12-05T16:32:49.744402Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sdf_dataset = Part_SDF_Dataset(train,64,2000)\n",
    "sdf_dataset_val = Part_SDF_Dataset(val,16,500)\n",
    "\n",
    "RT = np.array(part['RT'])\n",
    "sdf_dataset.transform_all_pc_with_Rt(RT)\n",
    "sdf_dataset_val.transform_all_pc_with_Rt(RT)\n",
    "\n",
    "train_dataloader = DataLoader(sdf_dataset, shuffle=True,batch_size=16, num_workers=0, drop_last = True)\n",
    "val_dataloader = DataLoader(sdf_dataset_val, shuffle=True,batch_size=16, num_workers=0, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T16:33:10.041732Z",
     "start_time": "2023-12-05T16:33:07.360374Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MyNet(64,latent_dim = 128, hyper_hidden_features=256,hidden_num=128)\n",
    "model.to(device=torch.device('cuda:0'))\n",
    "model.load_state_dict(torch.load(output_name+\"/model\"))#my_model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T17:02:15.433580Z",
     "start_time": "2023-11-24T17:02:14.488464Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "contour_plot(model,2000) # Change to 0 (Low Frequency Positional encodings) to see the smoother output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T14:03:16.645591Z",
     "start_time": "2022-07-27T14:03:16.631215Z"
    }
   },
   "source": [
    "# Validation Visulizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T16:33:10.169371Z",
     "start_time": "2023-12-05T16:33:10.042643Z"
    }
   },
   "outputs": [],
   "source": [
    "RTs = model.get_refine_poses(torch.arange(0,64).cuda(),affine=False).cpu().detach().numpy()\n",
    "sdf_dataset.set_sampling_RT(RTs[:,:3,:4])    \n",
    "RT_base=np.eye(4)\n",
    "RT_base[:3,:]= RTs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T16:33:11.015501Z",
     "start_time": "2023-12-05T16:33:10.170284Z"
    }
   },
   "outputs": [],
   "source": [
    "### Creating Interpolation Trajectories\n",
    "# #Handle: [0,12,16,53,42,8] Rim:[0,4,17,18,61,38] Cuboid: [24,56,60,61,57,25]\n",
    "mesh_list=estimate_mesh_traj_from_model(model, 2000, [24,56,60,61,57,25], num_of_steps=20, resolution=128,scale=0.5)\n",
    "draw_mesh_list(mesh_list,output_name+\"/interp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T16:33:15.738224Z",
     "start_time": "2023-12-05T16:33:13.639599Z"
    }
   },
   "outputs": [],
   "source": [
    "# Single Object Grasp Visualization\n",
    "mesh_list=list()\n",
    "part_points_list=list()\n",
    "sphere_base = trimesh.primitives.Sphere(radius = 0.5,subdivisions=6)\n",
    "sphere_base2 = trimesh.primitives.Sphere(radius = 0.1,subdivisions=3)\n",
    "gripper_mesh =  get_gripper_simple_mesh(np.zeros((3,)), np.eye(3), 0.10, 0.10, score=1)\n",
    "gripper_mesh.apply_scale(4)\n",
    "shape_tr = 0\n",
    "index = 0\n",
    "\n",
    "fc_color =np.random.rand(3) * 255 \n",
    "\n",
    "_,scale = compute_unit_sphere_transform(sdf_dataset.meshes_transformed[index])\n",
    "\n",
    "mesh2 = trimesh.Trimesh(vertices=sdf_dataset.meshes_transformed[index].vertices*scale,\n",
    "                        face_colors=fc_color, faces=sdf_dataset.meshes_transformed[index].faces)\n",
    "\n",
    "\n",
    "pc_inds,sdf_pos_inds,sdf_neg_inds= sdf_dataset.sample_within_sphere(index)\n",
    "\n",
    "points = np.copy(sdf_dataset.pointclouds[index][pc_inds][:8000])\n",
    "part_points_list.append(points)\n",
    "\n",
    "\n",
    "RT= np.eye(4)\n",
    "RT[:3,:] = sdf_dataset.sampling_RTs[index]\n",
    "RT_inv = find_inverse_RT_4x4(RT)\n",
    "\n",
    "mesh_list.append(mesh2)\n",
    "\n",
    "gripper_mesh_for_grasp = trimesh.Trimesh(vertices=gripper_mesh.vertices,\n",
    "                                     faces=gripper_mesh.faces,face_colors=[175,175,175])\n",
    "gripper_mesh_for_grasp.colors = np.tile(np.array([175,175,175]), (gripper_mesh_for_grasp.vertices.shape[0], 1))\n",
    "gripper_mesh_for_grasp.apply_transform(RT_inv)\n",
    "gripper_mesh_for_grasp.apply_transform(RT_base)\n",
    "\n",
    "mesh_list.append(gripper_mesh_for_grasp)\n",
    "\n",
    "shape_tr=shape_tr+1\n",
    "    \n",
    "scene = trimesh_show(part_points_list)\n",
    "scene.add_geometry(mesh_list)\n",
    "\n",
    "window = windowed.SceneViewer(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T12:16:55.540322Z",
     "start_time": "2023-08-30T12:16:50.509312Z"
    }
   },
   "outputs": [],
   "source": [
    "# Multi Object Grasp Visualization\n",
    "part_points_list = list()\n",
    "mesh_list = list()\n",
    "\n",
    "for obj_ind in range(0,4):  \n",
    "    color = np.random.rand(3) * 255\n",
    "    _,scale = compute_unit_sphere_transform(sdf_dataset.meshes[obj_ind])\n",
    "    \n",
    "    obj_mesh = trimesh.Trimesh(vertices=sdf_dataset.meshes_transformed[obj_ind].vertices,\n",
    "                            face_colors = color,faces=sdf_dataset.meshes_transformed[obj_ind].faces)\n",
    "    obj_mesh.apply_scale(scale)\n",
    "    obj_mesh.apply_translation([0,0,-1.5*obj_ind])  \n",
    "\n",
    "    pc_inds,sdf_pos_inds,sdf_neg_inds= sdf_dataset.sample_within_sphere(obj_ind,radius=0.8)\n",
    "    _,scale = compute_unit_sphere_transform(sdf_dataset.meshes[obj_ind])\n",
    "    points = np.copy(sdf_dataset.pointclouds[obj_ind][pc_inds][:])\n",
    "    points[:,2]-=1.5*obj_ind\n",
    "    part_points_list.append(points)\n",
    "\n",
    "    gripper_mesh =  get_gripper_simple_mesh(np.zeros((3,)), np.eye(3), 0.10, 0.10, score=1)\n",
    "    gripper_mesh.apply_scale(4)\n",
    "    gripper_mesh_for_grasp = trimesh.Trimesh(vertices=gripper_mesh.vertices,\n",
    "                                             faces=gripper_mesh.faces,face_colors=[175,175,175])\n",
    "    gripper_mesh_for_grasp.apply_translation([0,0,-1.5*obj_ind])\n",
    "    zero_frame =  get_coordinate_frame_mesh(0.2)\n",
    "    zero_frame.apply_translation([0,0,-1.5*obj_ind])\n",
    "    mesh_list.append(obj_mesh)\n",
    "    mesh_list.append(gripper_mesh_for_grasp)\n",
    "    mesh_list.append(zero_frame)\n",
    "    \n",
    "    RT= np.eye(4)\n",
    "    RT[:3,:] = sdf_dataset.sampling_RTs[obj_ind]\n",
    "    \n",
    "    obj_mesh = trimesh.Trimesh(vertices=sdf_dataset.meshes_transformed[obj_ind].vertices,\n",
    "                            face_colors = color,faces=sdf_dataset.meshes_transformed[obj_ind].faces)\n",
    "    obj_mesh.apply_scale(scale)\n",
    "    obj_mesh.apply_translation([3,0,-1.5*obj_ind])  \n",
    "\n",
    "    pc_inds,sdf_pos_inds,sdf_neg_inds= sdf_dataset.sample_within_sphere(obj_ind,RT[:3,:],radius=0.8)\n",
    "    _,scale = compute_unit_sphere_transform(sdf_dataset.meshes[obj_ind])\n",
    "    points = np.copy(sdf_dataset.pointclouds[obj_ind][pc_inds][:])\n",
    "    points[:,2]-=1.5*obj_ind\n",
    "    points[:,0]+=3\n",
    "    part_points_list.append(points)\n",
    "\n",
    "    gripper_mesh =  get_gripper_simple_mesh(np.zeros((3,)), np.eye(3), 0.10, 0.10, score=1)\n",
    "    gripper_mesh.apply_scale(4)\n",
    "    gripper_mesh_for_grasp = trimesh.Trimesh(vertices=gripper_mesh.vertices,\n",
    "                                             faces=gripper_mesh.faces,face_colors=[175,175,175])\n",
    "    gripper_mesh_for_grasp.apply_transform(find_inverse_RT_4x4(RT))    \n",
    "    gripper_mesh_for_grasp.apply_transform(RT_base)\n",
    "    \n",
    "    gripper_mesh_for_grasp.apply_translation([3,0,-1.5*obj_ind])\n",
    "    zero_frame =  get_coordinate_frame_mesh(0.2)\n",
    "    zero_frame.apply_transform(find_inverse_RT_4x4(RT))    \n",
    "    zero_frame.apply_transform(RT_base)\n",
    "\n",
    "    zero_frame.apply_translation([3,0,-1.5*obj_ind])\n",
    "    mesh_list.append(obj_mesh)\n",
    "    mesh_list.append(gripper_mesh_for_grasp)\n",
    "    mesh_list.append(zero_frame)    \n",
    "\n",
    "scene = trimesh_show(part_points_list)\n",
    "scene.add_geometry(mesh_list)\n",
    "window = windowed.SceneViewer(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T16:33:56.568773Z",
     "start_time": "2023-12-05T16:33:55.065141Z"
    }
   },
   "outputs": [],
   "source": [
    "# Multi Object Grasp + Reconstruction Visualization\n",
    "\n",
    "mesh_list=list()\n",
    "part_points_list=list()\n",
    "\n",
    "shape_tr = 0\n",
    "\n",
    "for index in range(0,4):\n",
    "    shape_Tr=[0,0,shape_tr*2]\n",
    "    fc_color = np.random.rand(3) * 255 \n",
    "    \n",
    "    _,scale = compute_unit_sphere_transform(sdf_dataset.meshes_transformed[index])\n",
    "    \n",
    "    mesh3 = trimesh.Trimesh(vertices=sdf_dataset.meshes_transformed[index].vertices*scale, \n",
    "                            faces=sdf_dataset.meshes_transformed[index].faces,face_colors=fc_color)\n",
    "    mesh3.apply_translation(shape_Tr)  \n",
    "\n",
    "    RT= np.eye(4)\n",
    "    RT[:3,:] = sdf_dataset.sampling_RTs[index]\n",
    "    RT_inv = find_inverse_RT_4x4(RT)   \n",
    "        \n",
    "    points = estimate_points_from_model(model, 2000, index, 64,0.5)\n",
    "    points = ((RT_inv@ to_hom_np(points).T).T)[:,:3]\n",
    "    points = ((RT_base@ to_hom_np(points).T).T)[:,:3]\n",
    "    points[:,:3]+=shape_Tr\n",
    "    part_points_list.append(points)    \n",
    "        \n",
    "    mesh_list.append(mesh3)\n",
    "    \n",
    "    gripper_mesh_for_grasp = trimesh.Trimesh(vertices=gripper_mesh.vertices,\n",
    "                                         faces=gripper_mesh.faces,face_colors=[175,175,175])\n",
    "    gripper_mesh_for_grasp.apply_transform(RT_inv)\n",
    "    gripper_mesh_for_grasp.apply_transform(RT_base)\n",
    "    gripper_mesh_for_grasp.apply_translation(shape_Tr)    \n",
    "    gripper_mesh_for_grasp.colors = np.tile(np.array([175,175,175]), (gripper_mesh_for_grasp.vertices.shape[0], 1))\n",
    "    mesh_list.append(gripper_mesh_for_grasp)\n",
    "    \n",
    "    shape_tr=shape_tr+1\n",
    "    \n",
    "scene = trimesh_show_green(part_points_list)\n",
    "scene.add_geometry(mesh_list)\n",
    "#scene.show()\n",
    "\n",
    "window = windowed.SceneViewer(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T16:36:53.101151Z",
     "start_time": "2023-12-05T16:36:46.407354Z"
    }
   },
   "outputs": [],
   "source": [
    "# Multi Object Grasp + Reconstruction Visualization\n",
    "\n",
    "mesh_list=list()\n",
    "part_points_list=list()\n",
    "\n",
    "shape_tr = 0\n",
    "\n",
    "for index in range(0,4):\n",
    "    shape_Tr=[0,0,shape_tr*2]\n",
    "    fc_color = np.random.rand(3) * 255 \n",
    "    \n",
    "    _,scale = compute_unit_sphere_transform(sdf_dataset.meshes_transformed[index])\n",
    "    \n",
    "    mesh3 = trimesh.Trimesh(vertices=sdf_dataset.meshes_transformed[index].vertices*scale, \n",
    "                            faces=sdf_dataset.meshes_transformed[index].faces,face_colors=fc_color)\n",
    "    mesh3.apply_translation(shape_Tr)  \n",
    "\n",
    "    RT= np.eye(4)\n",
    "    RT[:3,:] = sdf_dataset.sampling_RTs[index]\n",
    "    RT_inv = find_inverse_RT_4x4(RT)   \n",
    "        \n",
    "    v,t,_ = estimate_mesh_from_model(model, 2000, index, 128, scale=0.6)\n",
    "    points = ((RT_inv@ to_hom_np(v).T).T)[:,:3]\n",
    "    points = ((RT_base@ to_hom_np(points).T).T)[:,:3]\n",
    "    points[:,:3]+=shape_Tr\n",
    "    mesh = trimesh.Trimesh(vertices=points, faces=t, face_colors=[0,100,0])\n",
    "    points = estimate_points_from_model(model, 2000, index, 64,0.5)\n",
    "    points = ((RT_inv@ to_hom_np(points).T).T)[:,:3]\n",
    "    points = ((RT_base@ to_hom_np(points).T).T)[:,:3]\n",
    "    points[:,:3]+=shape_Tr\n",
    "    mesh_list.append(mesh)    \n",
    "        \n",
    "    mesh_list.append(mesh3)\n",
    "    \n",
    "    gripper_mesh_for_grasp = trimesh.Trimesh(vertices=gripper_mesh.vertices,\n",
    "                                         faces=gripper_mesh.faces,face_colors=[175,175,175])\n",
    "    gripper_mesh_for_grasp.apply_transform(RT_inv)\n",
    "    gripper_mesh_for_grasp.apply_transform(RT_base)\n",
    "    gripper_mesh_for_grasp.apply_translation(shape_Tr)    \n",
    "    gripper_mesh_for_grasp.colors = np.tile(np.array([175,175,175]), (gripper_mesh_for_grasp.vertices.shape[0], 1))\n",
    "    mesh_list.append(gripper_mesh_for_grasp)\n",
    "    \n",
    "    shape_tr=shape_tr+1\n",
    "  \n",
    "    \n",
    "scene = trimesh.Scene()\n",
    "scene.add_geometry(mesh_list)\n",
    "# scene = trimesh_show_green(part_points_list)\n",
    "# scene.add_geometry(mesh_list)\n",
    "#scene.show()\n",
    "\n",
    "window = windowed.SceneViewer(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T16:33:36.901427Z",
     "start_time": "2023-12-05T16:33:24.496055Z"
    }
   },
   "outputs": [],
   "source": [
    "# Multi Object Grasp + Reconstruction Visualization THREE-VIEW\n",
    "\n",
    "mesh_list=list()\n",
    "sphere_base = trimesh.primitives.Sphere(radius = 0.5,subdivisions=6)\n",
    "sphere_base2 = trimesh.primitives.Sphere(radius = 0.1,subdivisions=3)\n",
    "\n",
    "shape_tr = 0 \n",
    "for index in range(0,10):\n",
    "    fc_color = np.random.rand(3) * 255\n",
    "    v,t,_ = estimate_mesh_from_model(model, 2000, index, 128, scale=0.6)\n",
    "\n",
    "    mesh = trimesh.Trimesh(vertices=v, faces=t, face_colors=fc_color)\n",
    "    mesh.apply_translation([-2.5, 0, shape_tr*2.5])   \n",
    "    \n",
    "    _,scale = compute_unit_sphere_transform(sdf_dataset.meshes_transformed[index])\n",
    "\n",
    "    RT= np.eye(4)\n",
    "    RT[:3,:] = sdf_dataset.sampling_RTs[index]\n",
    "    RT_inv = find_inverse_RT_4x4(RT)\n",
    "    mesh2 = trimesh.Trimesh(vertices=sdf_dataset.meshes_transformed[index].vertices*scale,\n",
    "                            face_colors=fc_color, faces=sdf_dataset.meshes_transformed[index].faces)\n",
    "    mesh2.apply_translation([0, 0, shape_tr*2.5])\n",
    "    \n",
    "    mesh3 = trimesh.Trimesh(vertices=sdf_dataset.meshes_transformed[index].vertices*scale, \n",
    "                            faces=sdf_dataset.meshes_transformed[index].faces,face_colors=fc_color)\n",
    "\n",
    "    mesh3.apply_translation([3, 0, shape_tr*2.5])  \n",
    "    mesh_list.append(mesh)\n",
    "    mesh_list.append(mesh2)\n",
    "    mesh_list.append(mesh3)\n",
    "    \n",
    "    gripper_mesh_for_grasp = trimesh.Trimesh(vertices=gripper_mesh.vertices,\n",
    "                                         faces=gripper_mesh.faces,face_colors=[175,175,175])\n",
    "    gripper_mesh_for_grasp.apply_translation([0, 0, shape_tr*2.5])\n",
    "    gripper_mesh_for_grasp.colors = np.tile(np.array([175,175,175]), (gripper_mesh_for_grasp.vertices.shape[0], 1))\n",
    "    mesh_list.append(gripper_mesh_for_grasp)\n",
    "    \n",
    "    gripper_mesh_for_grasp = trimesh.Trimesh(vertices=gripper_mesh.vertices,\n",
    "                                         faces=gripper_mesh.faces,face_colors=[175,175,175])\n",
    "    gripper_mesh_for_grasp.apply_transform(RT_inv)\n",
    "    gripper_mesh_for_grasp.apply_translation([3, 0, shape_tr*2.5])\n",
    "    gripper_mesh_for_grasp.colors = np.tile(np.array([175,175,175]), (gripper_mesh_for_grasp.vertices.shape[0], 1))\n",
    "    mesh_list.append(gripper_mesh_for_grasp)\n",
    "    \n",
    "    shape_tr=shape_tr+1\n",
    "    \n",
    "scene = trimesh.Scene()\n",
    "scene.add_geometry(mesh_list)\n",
    "window = windowed.SceneViewer(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grasp_transfer_venv",
   "language": "python",
   "name": "grasp_transfer_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
